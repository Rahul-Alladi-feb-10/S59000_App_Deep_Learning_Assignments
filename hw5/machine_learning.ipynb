{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING MODEL EXECUTION ---\n",
      "Stage 1: Data Loaded.\n",
      "Stage 2: Feature Engineering and Imputation Complete.\n",
      " Stage 3: Grid Search CV Completed.\n",
      "\n",
      "==================================================\n",
      "BEST MODEL (Train Set) METRICS:\n",
      "  Accuracy: 0.8328\n",
      "  F1 Score: 0.7704\n",
      "  Confusion Matrix:\n",
      "[[492  57]\n",
      " [ 92 250]]\n",
      "==================================================\n",
      " Stage 4: Submission File Generated: svm_gridsearch_refined_submission.csv\n",
      "--- EXECUTION FINISHED \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start_time = time.time()\n",
    "print(\"--- STARTING MODEL EXECUTION ---\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print(\"Stage 1: Data Loaded.\")\n",
    "\n",
    "# Combine data for consistent imputation across sets\n",
    "full_data = pd.concat([train_data.drop('Survived', axis=1), test_data], ignore_index=True)\n",
    "train_len = len(train_data)\n",
    "Y_train = train_data['Survived']\n",
    "\n",
    "# --- Imputation ---\n",
    "full_data['Age'].fillna(full_data['Age'].median(), inplace=True)\n",
    "full_data['Fare'].fillna(full_data['Fare'].median(), inplace=True)\n",
    "full_data['Embarked'].fillna(full_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# --- Simple Feature Engineering (Family Size) ---\n",
    "full_data['FamilySize'] = full_data['SibSp'] + full_data['Parch']\n",
    "full_data['IsAlone'] = (full_data['FamilySize'] == 0).astype(int)\n",
    "\n",
    "# Drop irrelevant features\n",
    "X_full = full_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Separate back into training and test sets\n",
    "X_train = X_full.iloc[:train_len]\n",
    "X_test = X_full.iloc[train_len:]\n",
    "print(\"Stage 2: Feature Engineering and Imputation Complete.\")\n",
    "\n",
    "\n",
    "# Define column types for the ColumnTransformer\n",
    "numerical_features = ['Age', 'Fare', 'FamilySize', 'SibSp', 'Parch']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'IsAlone']\n",
    "\n",
    "# Create preprocessor for automatic scaling and encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the full pipeline: Preprocessing -> SVM Classifier\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Refined parameter grid\n",
    "param_grid_refined = {\n",
    "    'classifier__kernel': ['rbf', 'poly'],\n",
    "    'classifier__C': [0.5, 1, 2, 5],\n",
    "    'classifier__gamma': [0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform the Grid Search\n",
    "grid_search_refined = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    param_grid_refined,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search_refined.fit(X_train, Y_train)\n",
    "print(\" Stage 3: Grid Search CV Completed.\")\n",
    "\n",
    "# --- Evaluation Prints ---\n",
    "best_model_refined = grid_search_refined.best_estimator_\n",
    "Y_train_pred = best_model_refined.predict(X_train)\n",
    "\n",
    "# Calculate metrics on the training set\n",
    "train_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "train_f1 = f1_score(Y_train, Y_train_pred)\n",
    "conf_matrix = confusion_matrix(Y_train, Y_train_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"BEST MODEL (Train Set) METRICS:\")\n",
    "print(f\"  Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {train_f1:.4f}\")\n",
    "print(\"  Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate test predictions with the best model\n",
    "Y_test_pred_refined = best_model_refined.predict(X_test)\n",
    "\n",
    "# Create and save the new submission file\n",
    "submission_refined = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': Y_test_pred_refined\n",
    "})\n",
    "\n",
    "submission_file_name = 'svm_gridsearch_refined_submission.csv'\n",
    "submission_refined.to_csv(submission_file_name, index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\" Stage 4: Submission File Generated: {submission_file_name}\")\n",
    "print(f\"--- EXECUTION FINISHED \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
